Typically the compute nodes and the storage
nodes are the same, that is, the MapReduce
framework and the Hadoop Distributed File System
(see HDFS Architecture Guide) are running on the same set of nodes.
This configuration allows the framework to effectively
schedule tasks on the nodes where data is already present,
resulting in very high aggregate bandwidth across the cluster.
